{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIKHIL_SINGH_Session7.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nikhilsingh291/eip_theinkers/blob/master/NIKHIL_SINGH_Session7.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nGAM7AkNo5tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d3e81f8-3421-4304-9588-f0605746a6ce"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LnKAVzfPo7Ra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deep Learning for Visual Question Answering\n",
        "\n",
        "\n",
        "![alt text](https://avisingh599.github.io/images/vqa/sample_results.jpg)\n",
        "\n",
        "This is about answering general english questions based on images by deep learning.\n",
        "\n",
        "I will be using LSTM+CNN approach to solve this problem and get a better accuracy."
      ]
    },
    {
      "metadata": {
        "id": "wwovdGnMziqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eedc0544-0113-473e-8e52-171891f647e0"
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "%cd data\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gqPW7VjC00iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "ae392e24-e7e3-4c7f-ae9f-47855aa3069c"
      },
      "cell_type": "code",
      "source": [
        "# Downloads the training and validation sets from visualqa.org. \n",
        "\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Questions_Train_mscoco.zip\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Questions_Val_mscoco.zip\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Annotations_Train_mscoco.zip\n",
        "!wget http://visualqa.org/data/mscoco/vqa/Annotations_Val_mscoco.zip\n",
        "\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-06 17:09:21--  http://visualqa.org/data/mscoco/vqa/Questions_Train_mscoco.zip\r\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21985607 (21M) [application/zip]\n",
            "Saving to: ‘Questions_Train_mscoco.zip’\n",
            "\n",
            "Questions_Train_msc 100%[===================>]  20.97M  9.63MB/s    in 2.2s    \n",
            "\n",
            "2018-06-06 17:09:24 (9.63 MB/s) - ‘Questions_Train_mscoco.zip’ saved [21985607/21985607]\n",
            "\n",
            "--2018-06-06 17:09:25--  http://visualqa.org/data/mscoco/vqa/Questions_Val_mscoco.zip\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10594497 (10M) [application/zip]\n",
            "Saving to: ‘Questions_Val_mscoco.zip’\n",
            "\n",
            "Questions_Val_mscoc 100%[===================>]  10.10M  5.51MB/s    in 1.8s    \n",
            "\n",
            "2018-06-06 17:09:27 (5.51 MB/s) - ‘Questions_Val_mscoco.zip’ saved [10594497/10594497]\n",
            "\n",
            "--2018-06-06 17:09:28--  http://visualqa.org/data/mscoco/vqa/Annotations_Train_mscoco.zip\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12167843 (12M) [application/zip]\n",
            "Saving to: ‘Annotations_Train_mscoco.zip’\n",
            "\n",
            "Annotations_Train_m 100%[===================>]  11.60M  6.28MB/s    in 1.8s    \n",
            "\n",
            "2018-06-06 17:09:30 (6.28 MB/s) - ‘Annotations_Train_mscoco.zip’ saved [12167843/12167843]\n",
            "\n",
            "--2018-06-06 17:09:31--  http://visualqa.org/data/mscoco/vqa/Annotations_Val_mscoco.zip\n",
            "Resolving visualqa.org (visualqa.org)... 128.173.88.40\n",
            "Connecting to visualqa.org (visualqa.org)|128.173.88.40|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6031604 (5.8M) [application/zip]\n",
            "Saving to: ‘Annotations_Val_mscoco.zip’\n",
            "\n",
            "Annotations_Val_msc 100%[===================>]   5.75M  3.52MB/s    in 1.6s    \n",
            "\n",
            "2018-06-06 17:09:33 (3.52 MB/s) - ‘Annotations_Val_mscoco.zip’ saved [6031604/6031604]\n",
            "\n",
            "Archive:  Questions_Val_mscoco.zip\n",
            "  inflating: OpenEnded_mscoco_val2014_questions.json  \n",
            "  inflating: MultipleChoice_mscoco_val2014_questions.json  \n",
            "\n",
            "Archive:  Annotations_Train_mscoco.zip\n",
            "  inflating: mscoco_train2014_annotations.json  \n",
            "\n",
            "Archive:  Annotations_Val_mscoco.zip\n",
            "  inflating: mscoco_val2014_annotations.json  \n",
            "\n",
            "Archive:  Questions_Train_mscoco.zip\n",
            "  inflating: OpenEnded_mscoco_train2014_questions.json  \n",
            "  inflating: MultipleChoice_mscoco_train2014_questions.json  \n",
            "\n",
            "4 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N2pUh0pM0-xM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "98e25997-29ad-428c-dc8c-4a21bc381209"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "%cd ..\n",
        "!ls\n",
        "!mkdir features"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Annotations_Train_mscoco.zip\r\n",
            "Annotations_Val_mscoco.zip\r\n",
            "mscoco_train2014_annotations.json\r\n",
            "mscoco_val2014_annotations.json\r\n",
            "MultipleChoice_mscoco_train2014_questions.json\r\n",
            "MultipleChoice_mscoco_val2014_questions.json\r\n",
            "OpenEnded_mscoco_train2014_questions.json\r\n",
            "OpenEnded_mscoco_val2014_questions.json\r\n",
            "Questions_Train_mscoco.zip\r\n",
            "Questions_Val_mscoco.zip\r\n",
            "/content\n",
            "data  datalab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QBpjm3NK1e1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d8343f7c-c7ab-470e-c3d0-de8651a0e0c4"
      },
      "cell_type": "code",
      "source": [
        "%cd features\n",
        "!ls\n",
        "# Downloads and unzips the VGG features computed on the COCO dataset. \n",
        "\n",
        "!wget http://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip\n",
        "!unzip coco.zip -d ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/features\n",
            "--2018-06-06 17:14:32--  http://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip [following]\n",
            "--2018-06-06 17:14:32--  https://cs.stanford.edu/people/karpathy/deepimagesent/coco.zip\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 764830639 (729M) [application/zip]\n",
            "Saving to: ‘coco.zip’\n",
            "\n",
            "coco.zip             47%[========>           ] 344.96M  11.9MB/s    eta 30s    "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "coco.zip            100%[===================>] 729.40M  14.2MB/s    in 59s     \n",
            "\n",
            "2018-06-06 17:15:31 (12.3 MB/s) - ‘coco.zip’ saved [764830639/764830639]\n",
            "\n",
            "Archive:  coco.zip\n",
            "  inflating: ./coco/dataset.json     \n",
            "  inflating: ./coco/readme.txt       \n",
            "  inflating: ./coco/vgg_feats.mat    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_iyENfrO2Yc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f316575-5c86-444b-bcd4-7b4e6bd1ee95"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "%cd .."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coco  coco.zip\r\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ctvGZMoR2eSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        },
        "outputId": "72be606e-cc42-4932-8bfa-2fb262e38fc1"
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls\n",
        "!pip install spacy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "data  datalab  features\n",
            "Collecting spacy\n",
            "  Using cached https://files.pythonhosted.org/packages/3c/31/e60f88751e48851b002f78a35221d12300783d5a43d4ef12fbf10cca96c3/spacy-2.0.11.tar.gz\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.3)\n",
            "Collecting murmurhash<0.29,>=0.28 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/5e/31/c8c1ecafa44db30579c8c457ac7a0f819e8b1dbc3e58308394fff5ff9ba7/murmurhash-0.28.0.tar.gz\n",
            "Collecting cymem<1.32,>=1.30 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/f8/9e/273fbea507de99166c11cd0cb3fde1ac01b5bc724d9a407a2f927ede91a1/cymem-1.31.2.tar.gz\n",
            "Collecting preshed<2.0.0,>=1.0.0 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/1b/ac/7c17b1fd54b60972785b646d37da2826311cca70842c011c4ff84fbe95e0/preshed-1.0.0.tar.gz\n",
            "Collecting thinc<6.11.0,>=6.10.1 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/55/fd/e9f36081e6f53699943381858848f3b4d759e0dd03c43b98807dde34c252/thinc-6.10.2.tar.gz\n",
            "Collecting plac<1.0.0,>=0.9.6 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Collecting pathlib (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz\n",
            "Collecting ujson>=1.35 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz\n",
            "Collecting dill<0.3,>=0.2 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/91/a0/19d4d31dee064fc553ae01263b5c55e7fb93daff03a69debbedee647c5a0/dill-0.2.7.1.tar.gz\n",
            "Collecting regex==2017.4.5 (from spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz\n",
            "Collecting wrapt (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
            "Collecting tqdm<5.0.0,>=4.10.0 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl\n",
            "Collecting cytoolz<0.9,>=0.8 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/0f/e6/ccc124714dcc1bd511e64ddafb4d5d20ada2533b92e3173a4cf09e0d0831/cytoolz-0.8.2.tar.gz\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.1->spacy) (1.1.0)\n",
            "Collecting msgpack-python (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/8a/20/6eca772d1a5830336f84aca1d8198e5a3f4715cd1c7fc36d3cc7f7185091/msgpack-python-0.5.6.tar.gz\n",
            "Collecting msgpack-numpy==0.4.1 (from thinc<6.11.0,>=6.10.1->spacy)\n",
            "  Using cached https://files.pythonhosted.org/packages/2e/43/393e30e2768b0357541ac95891f96b80ccc4d517e0dd2fa3042fc8926538/msgpack_numpy-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.11.0,>=6.10.1->spacy) (0.9.0)\n",
            "Building wheels for collected packages: spacy, murmurhash, cymem, preshed, thinc, pathlib, ujson, dill, regex, wrapt, cytoolz, msgpack-python\n",
            "  Running setup.py bdist_wheel for spacy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/fb/00/28/75c85d5135e7d9a100639137d1847d41e914ed16c962d467e4\n",
            "  Running setup.py bdist_wheel for murmurhash ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b8/94/a4/f69f8664cdc1098603df44771b7fec5fd1b3d8364cdd83f512\n",
            "  Running setup.py bdist_wheel for cymem ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/55/8d/4a/f6328252aa2aaec0b1cb906fd96a1566d77f0f67701071ad13\n",
            "  Running setup.py bdist_wheel for preshed ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/8f/85/06/2d132fb649a6bbcab22487e4147880a55b0dd0f4b18fdfd6b5\n",
            "  Running setup.py bdist_wheel for thinc ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d8/5c/3e/9acf5d9974fb1c9e7b467563ea5429c9325f67306e93147961\n",
            "  Running setup.py bdist_wheel for pathlib ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f9/b2/4a/68efdfe5093638a9918bd1bb734af625526e849487200aa171\n",
            "  Running setup.py bdist_wheel for ujson ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
            "  Running setup.py bdist_wheel for dill ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/99/c4/ed/1b64d2d5809e60d5a3685530432f6159d6a9959739facb61f2\n",
            "  Running setup.py bdist_wheel for regex ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "  Running setup.py bdist_wheel for wrapt ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
            "  Running setup.py bdist_wheel for cytoolz ... \u001b[?25l-\b \b\\\b \b|\b \b/"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f8/b1/86/c92e4d36b690208fff8471711b85eaa6bc6d19860a86199a09\n",
            "  Running setup.py bdist_wheel for msgpack-python ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d5/de/86/7fa56fda12511be47ea0808f3502bc879df4e63ab168ec0406\n",
            "Successfully built spacy murmurhash cymem preshed thinc pathlib ujson dill regex wrapt cytoolz msgpack-python\n",
            "Installing collected packages: murmurhash, cymem, preshed, wrapt, tqdm, cytoolz, plac, dill, pathlib, msgpack-python, msgpack-numpy, thinc, ujson, regex, spacy\n",
            "Successfully installed cymem-1.31.2 cytoolz-0.8.2 dill-0.2.7.1 msgpack-numpy-0.4.1 msgpack-python-0.5.6 murmurhash-0.28.0 pathlib-1.0.1 plac-0.9.6 preshed-1.0.0 regex-2017.4.5 spacy-2.0.11 thinc-6.10.2 tqdm-4.23.4 ujson-1.35 wrapt-1.10.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4oPkQDrYlrvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4b926ffb-6c1f-4593-9f9e-a389cc3c907b"
      },
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download en\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 37.4MB 60.1MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "  Running setup.py install for en-core-web-sm ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n",
            "Cloning into 'visual_q_ans'...\n",
            "warning: redirecting to https://github.com/nikhilsingh291/visual_q_ans.git/\n",
            "remote: Counting objects: 19, done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 19 (delta 7), reused 12 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n",
            "data  datalab  features  visual_q_ans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j1wiSfOBSMRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c4d850a2-d69a-47de-9aac-2860b2018a7c"
      },
      "cell_type": "code",
      "source": [
        "'''!ls\n",
        "%cd\n",
        "!ls\n",
        "!rm -rf visual_q_ans/\n",
        "!ls\n",
        "'''\n",
        "!pip3 install progressbar"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting progressbar\r\n",
            "  Using cached https://files.pythonhosted.org/packages/0f/e1/f30b72ecabba259c7c38dd0eb944a173effced3fd7de2c9c2902bd6f649a/progressbar-2.3.tar.gz\n",
            "    Complete output from command python setup.py egg_info:\n",
            "    Traceback (most recent call last):\n",
            "      File \"<string>\", line 1, in <module>\n",
            "      File \"/tmp/pip-install-8zw8qd5w/progressbar/setup.py\", line 5, in <module>\n",
            "        import progressbar\n",
            "      File \"/tmp/pip-install-8zw8qd5w/progressbar/progressbar/__init__.py\", line 59, in <module>\n",
            "        from progressbar.widgets import *\n",
            "      File \"/tmp/pip-install-8zw8qd5w/progressbar/progressbar/widgets.py\", line 121, in <module>\n",
            "        class FileTransferSpeed(Widget):\n",
            "      File \"/usr/lib/python3.6/abc.py\", line 133, in __new__\n",
            "        cls = super().__new__(mcls, name, bases, namespace, **kwargs)\n",
            "    ValueError: 'format' in __slots__ conflicts with class variable\n",
            "    \n",
            "    ----------------------------------------\n",
            "\u001b[31mCommand \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-install-8zw8qd5w/progressbar/\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U8jtq2ofmHyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ac420047-efd2-4157-99af-eea342ac383c"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"import operator\n",
        "from itertools import zip_longest\n",
        "from collections import defaultdict\n",
        "\n",
        "def selectFrequentAnswers(questions_train, answers_train, images_train, maxAnswers):\n",
        "\tanswer_fq= defaultdict(int)\n",
        "\t#build a dictionary of answers\n",
        "\tfor answer in answers_train:\n",
        "\t\tanswer_fq[answer] += 1\n",
        "\n",
        "\tsorted_fq = sorted(answer_fq.items(), key=operator.itemgetter(1), reverse=True)[0:maxAnswers]\n",
        "\ttop_answers, top_fq = zip(*sorted_fq)\n",
        "\tnew_answers_train=[]\n",
        "\tnew_questions_train=[]\n",
        "\tnew_images_train=[]\n",
        "\t#only those answer which appear int he top 1K are used for training\n",
        "\tfor answer,question,image in zip(answers_train, questions_train, images_train):\n",
        "\t\tif answer in top_answers:\n",
        "\t\t\tnew_answers_train.append(answer)\n",
        "\t\t\tnew_questions_train.append(question)\n",
        "\t\t\tnew_images_train.append(image)\n",
        "\n",
        "\treturn (new_questions_train,new_answers_train,new_images_train)\n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "    args = [iter(iterable)] * n\n",
        "    return izip_longest(*args, fillvalue=fillvalue)\n",
        "    \"\"\"\n",
        "\n",
        "!git clone http://github.com/nikhilsingh291/visual_q_ans.git\n",
        "!ls\n",
        "%cd visual_q_ans/\n",
        "!ls\n",
        "\n",
        "!python dumpText.py"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'visual_q_ans'...\n",
            "warning: redirecting to https://github.com/nikhilsingh291/visual_q_ans.git/\n",
            "remote: Counting objects: 22, done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 22 (delta 9), reused 15 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n",
            "data  datalab  features  visual_q_ans\n",
            "/content/visual_q_ans\n",
            "dumpText.py\t     features.py  own_image.py\tutils.py\n",
            "extract_features.py  mainpy.py\t  README.md\n",
            "Traceback (most recent call last):\n",
            "  File \"dumpText.py\", line 3, in <module>\n",
            "    import progressbar\n",
            "ModuleNotFoundError: No module named 'progressbar'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CH0B8UwF16Mw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "def get_questions_tensor_timeseries(questions, nlp, timesteps):\n",
        "\t'''\n",
        "\tReturns a time series of word vectors for tokens in the question\n",
        "\n",
        "\tInput:\n",
        "\tquestions: list of unicode objects\n",
        "\tnlp: an instance of the class English() from spacy.en\n",
        "\ttimesteps: the number of \n",
        "\n",
        "\tOutput:\n",
        "\tA numpy ndarray of shape: (nb_samples, timesteps, word_vec_dim)\n",
        "\t'''\n",
        "\tassert not isinstance(questions, basestring)\n",
        "\tnb_samples = len(questions)\n",
        "\tword_vec_dim = nlp(questions[0])[0].vector.shape[0]\n",
        "\tquestions_tensor = np.zeros((nb_samples, timesteps, word_vec_dim))\n",
        "\tfor i in xrange(len(questions)):\n",
        "\t\ttokens = nlp(questions[i])\n",
        "\t\tfor j in xrange(len(tokens)):\n",
        "\t\t\tif j<timesteps:\n",
        "\t\t\t\tquestions_tensor[i,j,:] = tokens[j].vector\n",
        "\n",
        "\treturn questions_tensor\n",
        "\n",
        "def get_questions_matrix_sum(questions, nlp):\n",
        "\t'''\n",
        "\tSums the word vectors of all the tokens in a question\n",
        "\t\n",
        "\tInput:\n",
        "\tquestions: list of unicode objects\n",
        "\tnlp: an instance of the class English() from spacy.en\n",
        "\n",
        "\tOutput:\n",
        "\tA numpy array of shape: (nb_samples, word_vec_dim)\t\n",
        "\t'''\n",
        "\tassert not isinstance(questions, basestring)\n",
        "\tnb_samples = len(questions)\n",
        "\tword_vec_dim = nlp(questions[0])[0].vector.shape[0]\n",
        "\tquestions_matrix = np.zeros((nb_samples, word_vec_dim))\n",
        "\tfor i in xrange(len(questions)):\n",
        "\t\ttokens = nlp(questions[i])\n",
        "\t\tfor j in xrange(len(tokens)):\n",
        "\t\t\tquestions_matrix[i,:] += tokens[j].vector\n",
        "\n",
        "\treturn questions_matrix\n",
        "\n",
        "def get_answers_matrix(answers, encoder):\n",
        "\t'''\n",
        "\tConverts string objects to class labels\n",
        "\n",
        "\tInput:\n",
        "\tanswers:\ta list of unicode objects\n",
        "\tencoder:\ta scikit-learn LabelEncoder object\n",
        "\n",
        "\tOutput:\n",
        "\tA numpy array of shape (nb_samples, nb_classes)\n",
        "\t'''\n",
        "\tassert not isinstance(answers, basestring)\n",
        "\ty = encoder.transform(answers) #string to numerical class\n",
        "\tnb_classes = encoder.classes_.shape[0]\n",
        "\tY = np_utils.to_categorical(y, nb_classes)\n",
        "\treturn Y\n",
        "\n",
        "def get_images_matrix(img_coco_ids, img_map, VGGfeatures):\n",
        "\t'''\n",
        "\tGets the 4096-dimensional CNN features for the given COCO\n",
        "\timages\n",
        "\t\n",
        "\tInput:\n",
        "\timg_coco_ids: \tA list of strings, each string corresponding to\n",
        "\t\t\t\t  \tthe MS COCO Id of the relevant image\n",
        "\timg_map: \t\tA dictionary that maps the COCO Ids to their indexes \n",
        "\t\t\t\t\tin the pre-computed VGG features matrix\n",
        "\tVGGfeatures: \tA numpy array of shape (nb_dimensions,nb_images)\n",
        "\n",
        "\tOuput:\n",
        "\tA numpy matrix of size (nb_samples, nb_dimensions)\n",
        "\t'''\n",
        "\tassert not isinstance(img_coco_ids, basestring)\n",
        "\tnb_samples = len(img_coco_ids)\n",
        "\tnb_dimensions = VGGfeatures.shape[0]\n",
        "\timage_matrix = np.zeros((nb_samples, nb_dimensions))\n",
        "\tfor j in xrange(len(img_coco_ids)):\n",
        "\t\timage_matrix[j,:] = VGGfeatures[:,img_map[img_coco_ids[j]]]\n",
        "\n",
        "\treturn image_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AFvmv-Eho8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import sys\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout, Reshape\n",
        "from keras.layers import Merge\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from keras.callbacks import ModelCheckpoint, RemoteMonitor\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#from spacy.en import English\n",
        "\n",
        "#from utils import grouper, selectFrequentAnswers\n",
        "#from features import get_images_matrix, get_answers_matrix, get_questions_tensor_timeseries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tX_x_QPh2A7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e310bfe3-b935-4870-e83e-b46c407adb25"
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RaqO0UPaqB86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f2e82965-c84d-410c-9513-1e18845446f0"
      },
      "cell_type": "code",
      "source": [
        "word_vec_dim= 300\n",
        "img_dim = 4096\n",
        "max_len = 30\n",
        "nb_classes = 1000\n",
        "\n",
        "questions_train = open('../data/preprocessed/questions_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
        "questions_lengths_train = open('../data/preprocessed/questions_lengths_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
        "answers_train = open('../data/preprocessed/answers_train2014_modal.txt', 'r').read().decode('utf8').splitlines()\n",
        "images_train = open('../data/preprocessed/images_train2014.txt', 'r').read().decode('utf8').splitlines()\n",
        "vgg_model_path = '../features/coco/vgg_feats.mat'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-33180ee1d612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mquestions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/preprocessed/questions_train2014.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mquestions_lengths_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/preprocessed/questions_lengths_train2014.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0manswers_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/preprocessed/answers_train2014_modal.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/preprocessed/questions_train2014.txt'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KdqDLY75qF1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}